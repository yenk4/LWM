{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31e7078-71e2-48bf-b6f0-81cdfe1d485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bef4000-2b5d-4184-9962-4e71f20d70f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/envs/lwm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from absl.app import run\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import decord\n",
    "from functools import cached_property\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax.experimental.pjit import pjit\n",
    "from jax.sharding import PartitionSpec as PS\n",
    "from transformers import GenerationConfig\n",
    "from tux import (\n",
    "    define_flags_with_default, StreamingCheckpointer, JaxDistributedConfig,\n",
    "    set_random_seed, get_float_dtype_by_name, JaxRNG, next_rng,\n",
    "    match_partition_rules, make_shard_and_gather_fns,\n",
    "    with_sharding_constraint, tree_apply, open_file\n",
    ")\n",
    "from lwm.vision_llama import VideoLLaMAConfig, FlaxVideoLLaMAForCausalLM\n",
    "from lwm.vqgan import VQGAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa417365-f0b9-492f-8376-57d94bf2539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_rng(seed):\n",
    "#     global jax_utils_rng\n",
    "#     jax_utils_rng = JaxRNG.from_seed(seed)\n",
    "\n",
    "\n",
    "def next_rng(*args, **kwargs):\n",
    "    global jax_utils_rng\n",
    "    jax_utils_rng = JaxRNG.from_seed(SEED)\n",
    "    return jax_utils_rng(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a1a8a5-45ea-4c32-9872-85a4f83645e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self):\n",
    "        self.mesh = VideoLLaMAConfig.get_jax_mesh(args['mesh_dim'])\n",
    "        self.vqgan = VQGAN(args['vqgan_checkpoint'], replicate=False)\n",
    "        self.prefix_tokenizer = VideoLLaMAConfig.get_tokenizer(\n",
    "            args['tokenizer'], truncation_side='left', padding_side='left'\n",
    "        )\n",
    "        self.tokenizer = VideoLLaMAConfig.get_tokenizer(args['tokenizer'])\n",
    "        self.n_tokens_per_frame = 257\n",
    "        self.min_buffer_size = 256\n",
    "        self.sharded_rng = next_rng()\n",
    "        self._load_model()\n",
    "\n",
    "    @property\n",
    "    def block_size(self):\n",
    "        return max(self.config.scan_query_chunk_size, self.config.scan_key_chunk_size) * self.mesh.shape['sp']\n",
    "    \n",
    "    @property\n",
    "    def data_dim(self):\n",
    "        return self.mesh.shape['dp'] * self.mesh.shape['fsdp']\n",
    "\n",
    "    def _process_frame(self, image, size):\n",
    "        width, height = image.size\n",
    "        if width < height:\n",
    "            new_width = size\n",
    "            new_height = int(size * height / width)\n",
    "        else:\n",
    "            new_height = size\n",
    "            new_width = int(size * width / height)\n",
    "        image = image.resize((new_width, new_height))\n",
    "\n",
    "        left = (new_width - size) / 2\n",
    "        top = (new_height - size) / 2\n",
    "        right = (new_width + size) / 2\n",
    "        bottom = (new_height + size) / 2\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "        return np.array(image, dtype=np.float32) / 127.5 - 1\n",
    "    \n",
    "    def _read_process_vision(self, path, max_n_frames):\n",
    "        f = open_file(path, 'rb')\n",
    "        if path.endswith('.png') or path.endswith('.jpg'):\n",
    "            image = Image.open(f).convert('RGB')\n",
    "            vision = self._process_frame(image, 256)[None]\n",
    "        else:\n",
    "            vr = decord.VideoReader(f, ctx=decord.cpu(0))\n",
    "            duration = len(vr)\n",
    "            if duration <= max_n_frames:\n",
    "                frame_id_list = list(range(duration))\n",
    "            else:\n",
    "                frame_id_list = np.linspace(0, duration - 1, max_n_frames, dtype=int).tolist()\n",
    "            video = vr.get_batch(frame_id_list).asnumpy()\n",
    "            vision = np.stack([self._process_frame(Image.fromarray(frame), 256) for frame in video])\n",
    "\n",
    "        B = 1\n",
    "        encodings = []\n",
    "        for i in range(0, len(vision), 1):\n",
    "            v = vision[i:i + B]\n",
    "            if len(v) % B == 0:\n",
    "                n_pad = 0\n",
    "            else:\n",
    "                n_pad = B - len(v) % B\n",
    "            v = np.pad(v, ((n_pad, 0), (0, 0), (0, 0), (0, 0)))\n",
    "            enc = jax.device_get(self.vqgan.encode(v))[1].astype(int)\n",
    "            enc = enc[n_pad:]\n",
    "            for t in range(len(enc)):\n",
    "                encodings.extend(enc[t].reshape(-1).tolist())\n",
    "                if t == len(enc) - 1:\n",
    "                    encodings.append(8193)\n",
    "                else:\n",
    "                    encodings.append(8192)\n",
    "        return encodings\n",
    "\n",
    "    def construct_input(self, prompts, max_n_frames):\n",
    "        max_input_length = max_n_frames * self.n_tokens_per_frame + self.min_buffer_size\n",
    "        max_input_length = int(math.ceil(max_input_length / self.block_size) * self.block_size)\n",
    "\n",
    "        vision_start = self.tokenizer.encode('<vision>')\n",
    "        vision_end = self.tokenizer.encode('</vision>')\n",
    "\n",
    "        input_ids = np.zeros((len(prompts), max_input_length), dtype=int)\n",
    "        vision_masks = np.zeros((len(prompts), max_input_length), dtype=bool)\n",
    "        attention_mask = np.zeros((len(prompts), max_input_length), dtype=int)\n",
    "        for i, prompt in enumerate(tqdm(prompts)):\n",
    "            vision = self._read_process_vision(prompt['input_path'], max_n_frames)\n",
    "            text_1 = self.tokenizer.encode(f\"<s>You are a helpful assistant. USER: {prompt['question']}\\n\")\n",
    "            tail = self.tokenizer.encode(\" ASSISTANT:\")\n",
    "            \n",
    "            tokens, vm = [], []\n",
    "            tokens.extend(text_1)\n",
    "            vm.extend([False] * len(text_1))\n",
    "            tokens.extend(vision_start)\n",
    "            vm.extend([False] * len(vision_start))\n",
    "            tokens.extend(vision)\n",
    "            vm.extend([True] * len(vision))\n",
    "            tokens.extend(vision_end)\n",
    "            vm.extend([False] * len(vision_end))\n",
    "            tokens.extend(tail)\n",
    "            vm.extend([False] * len(tail))\n",
    "            assert len(tokens) < max_input_length, (len(tokens), max_input_length)\n",
    "            assert len(tokens) == len(vm)\n",
    "            input_ids[i, -len(tokens):] = tokens\n",
    "            vision_masks[i, -len(tokens):] = vm\n",
    "            attention_mask[i, -len(tokens):] = 1\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'vision_masks': vision_masks,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "             \n",
    "\n",
    "    def _load_model(self):\n",
    "        if args['load_llama_config'] != '':\n",
    "            llama_config = VideoLLaMAConfig.load_config(args['load_llama_config'])\n",
    "            updates = VideoLLaMAConfig(**args['llama'])\n",
    "            llama_config.update(dict(\n",
    "                remat_block=updates.remat_block,\n",
    "                remat_attention=updates.remat_attention,\n",
    "                remat_mlp=updates.remat_mlp,\n",
    "                scan_attention=updates.scan_attention,\n",
    "                scan_mlp=updates.scan_mlp,\n",
    "                scan_query_chunk_size=updates.scan_query_chunk_size,\n",
    "                scan_key_chunk_size=updates.scan_key_chunk_size,\n",
    "                scan_mlp_chunk_size=updates.scan_mlp_chunk_size,\n",
    "                scan_layers=updates.scan_layers,\n",
    "                param_scan_axis=updates.param_scan_axis,\n",
    "            ))\n",
    "        else:\n",
    "            llama_config = VideoLLaMAConfig(**args['llama'])\n",
    "\n",
    "        if args['update_llama_config'] != '':\n",
    "            llama_config.update(dict(eval(args['update_llama_config'])))\n",
    "\n",
    "        llama_config.update(dict(\n",
    "            bos_token_id=self.tokenizer.bos_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "        ))\n",
    "        llama_config.update(dict(mesh_dim=args['mesh_dim']))\n",
    "        self.config = llama_config\n",
    "\n",
    "        self.model = FlaxVideoLLaMAForCausalLM(\n",
    "            llama_config, \n",
    "            input_shape=(512, self.block_size), \n",
    "            seed=args['seed'], \n",
    "            _do_init=False,\n",
    "            dtype=get_float_dtype_by_name(args['dtype']),\n",
    "        )\n",
    "\n",
    "        with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "            _, self.params = StreamingCheckpointer.load_trainstate_checkpoint(\n",
    "                    args['load_checkpoint'], disallow_trainstate=True, max_buffer_size=32 * 2 ** 30\n",
    "            )\n",
    "        self.model_ps = match_partition_rules(\n",
    "            VideoLLaMAConfig.get_partition_rules(llama_config.scan_layers, llama_config.param_scan_axis), self.params\n",
    "        )\n",
    "        shard_fns, _ = make_shard_and_gather_fns(\n",
    "            self.model_ps, get_float_dtype_by_name(args['dtype'])\n",
    "        )\n",
    "\n",
    "        with self.mesh:\n",
    "            self.params = tree_apply(shard_fns, self.params)\n",
    "\n",
    "    @cached_property\n",
    "    def _forward_generate(self):\n",
    "        def fn(params, rng, batch):\n",
    "            batch = with_sharding_constraint(batch, PS(('dp', 'fsdp'), 'sp'))\n",
    "            rng_generator = JaxRNG(rng)\n",
    "            output = self.model.generate(\n",
    "                batch['input_ids'],\n",
    "                vision_masks=batch['vision_masks'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                params=params['params'],\n",
    "                prng_key=rng_generator(),\n",
    "                generation_config=GenerationConfig(\n",
    "                    max_new_tokens=self.block_size,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                    temperature=args['temperature'],\n",
    "                    do_sample=True,\n",
    "                )\n",
    "            ).sequences[:, batch['input_ids'].shape[1]:]\n",
    "            return output, rng_generator()\n",
    "        return pjit(\n",
    "            fn,\n",
    "            in_shardings=(self.model_ps, PS(), PS()),\n",
    "            out_shardings=(PS(), PS())\n",
    "        )\n",
    "\n",
    "    def __call__(self, prompts, max_n_frames):\n",
    "        batch = self.construct_input(prompts, max_n_frames)\n",
    "        print(batch)\n",
    "        with self.mesh:\n",
    "            output, self.sharded_rng = self._forward_generate(\n",
    "                self.params, self.sharded_rng, batch\n",
    "            )\n",
    "            output = jax.device_get(output)\n",
    "        output_text = []\n",
    "        for text in list(self.tokenizer.batch_decode(output, skip_special_tokens=True)):\n",
    "            if self.tokenizer.eos_token in text:\n",
    "                text = text.split(self.tokenizer.eos_token, maxsplit=1)[0]\n",
    "            output_text.append(text)\n",
    "        return output_text\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6124b48b-9eb2-444f-8fe7-47e17773668e",
   "metadata": {},
   "source": [
    "s = f\"--prompt='' --input_file='{INPUT_FILE}' --vqgan_checkpoint='{VQGAN_CHECKPOINT}' --mesh_dim='!1,1,-1,1' --dtype='fp32' --load_llama_config='7b' --update_llama_config=\\\"dict(sample_mode='text',theta=50000000,max_sequence_length=131072,use_flash_attention=False,scan_attention=False,scan_query_chunk_size=128,scan_key_chunk_size=128,remat_attention='',scan_mlp=False,scan_mlp_chunk_size=2048,remat_mlp='',remat_block='',scan_layers=True)\\\" --load_checkpoint='params::{LWM_CHECKPOINT}' --tokenizer.vocab_file='{LLAMA_TOKENIZER_PATH}'\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "a17ffe77-96b6-484f-9411-2be987c150b3",
   "metadata": {},
   "source": [
    "argv = s.split()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4eeb700-a25a-47c2-b8aa-a1ad9556bebd",
   "metadata": {},
   "source": [
    "argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259969c2-f738-4a89-ab71-f4902d42b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "PROMPT = \"What is the video about?\"\n",
    "INPUT_FILE = \"/workspace/LWM/videos/fd7f1717-1ce1-4464-ae6b-68974b167c1f.mp4\"\n",
    "VQGAN_CHECKPOINT = \"/workspace/LWM/LWM-Chat-32K-Jax/vqgan\"\n",
    "MAX_N_FRAMES = 8  # default was set to 8\n",
    "LWM_CHECKPOINT = \"params::/workspace/LWM/LWM-Chat-32K-Jax/params\"\n",
    "LLAMA_TOKENIZER_PATH = \"/workspace/LWM/LWM-Chat-32K-Jax/tokenizer.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9379c7cb-d0cc-48a4-8017-10f10a5f332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'prompt': PROMPT,\n",
    "    'input_file': INPUT_FILE,\n",
    "    'vqgan_checkpoint': VQGAN_CHECKPOINT,\n",
    "    'temperature': 0.2,\n",
    "    'max_n_frames': MAX_N_FRAMES,\n",
    "    'seed':SEED,\n",
    "    'mesh_dim':'1,-1,1,1',\n",
    "    'dtype':'fp32',\n",
    "    'load_llama_config':'7b',\n",
    "    'update_llama_config':\"dict(sample_mode='text',theta=50000000,max_sequence_length=131072,use_flash_attention=False,scan_attention=False,scan_query_chunk_size=128,scan_key_chunk_size=128,remat_attention='',scan_mlp=False,scan_mlp_chunk_size=2048,remat_mlp='',remat_block='',scan_layers=True)\",\n",
    "    'load_checkpoint': LWM_CHECKPOINT,\n",
    "    'tokenizer': VideoLLaMAConfig.get_tokenizer_config(),\n",
    "    'llama': VideoLLaMAConfig.get_default_config(),\n",
    "    'jax_distributed': JaxDistributedConfig.get_default_config(),\n",
    "}\n",
    "\n",
    "args['tokenizer'].vocab_file = LLAMA_TOKENIZER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31a57be-eb8c-4548-9256-22aa075725b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1225e0-e470-4585-872b-fa48fcbbc92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[    0,     0,     0, ...,  9047, 13566, 29901]]), 'vision_masks': array([[False, False, False, ..., False, False, False]]), 'attention_mask': array([[0, 0, 0, ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "prompts = [{'input_path': args['input_file'], 'question': args['prompt']}]\n",
    "output = sampler(prompts, args['max_n_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22756dcb-32bd-4329-b52b-8282f6aaf573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The video is about a woman who is massaging her belly button and neck while wearing a bra.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45233bc-f1fe-44f3-970c-d1fff65bae21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwm",
   "language": "python",
   "name": "lwm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
